{
    "name": "root",
    "gauges": {
        "AgentVer5.Policy.Entropy.mean": {
            "value": 2.401935338973999,
            "min": 2.401935338973999,
            "max": 2.7777926921844482,
            "count": 10
        },
        "AgentVer5.Policy.Entropy.sum": {
            "value": 120140.0,
            "min": 120140.0,
            "max": 138964.640625,
            "count": 10
        },
        "AgentVer5.Environment.EpisodeLength.mean": {
            "value": 50.77846790890269,
            "min": 37.2170245398773,
            "max": 52.545551982851016,
            "count": 10
        },
        "AgentVer5.Environment.EpisodeLength.sum": {
            "value": 49052.0,
            "min": 48531.0,
            "max": 49146.0,
            "count": 10
        },
        "AgentVer5.Step.mean": {
            "value": 499989.0,
            "min": 49963.0,
            "max": 499989.0,
            "count": 10
        },
        "AgentVer5.Step.sum": {
            "value": 499989.0,
            "min": 49963.0,
            "max": 499989.0,
            "count": 10
        },
        "AgentVer5.Policy.ExtrinsicValueEstimate.mean": {
            "value": 0.33205446600914,
            "min": -0.6733353137969971,
            "max": 0.40031033754348755,
            "count": 10
        },
        "AgentVer5.Policy.ExtrinsicValueEstimate.sum": {
            "value": 417.0604248046875,
            "min": -1058.483154296875,
            "max": 501.9891662597656,
            "count": 10
        },
        "AgentVer5.Environment.CumulativeReward.mean": {
            "value": 0.3089503033190781,
            "min": -0.45800229609926785,
            "max": 0.45840791493207533,
            "count": 10
        },
        "AgentVer5.Environment.CumulativeReward.sum": {
            "value": 298.4459930062294,
            "min": -597.2349941134453,
            "max": 428.1529925465584,
            "count": 10
        },
        "AgentVer5.Policy.ExtrinsicReward.mean": {
            "value": 0.3089503033190781,
            "min": -0.45800229609926785,
            "max": 0.45840791493207533,
            "count": 10
        },
        "AgentVer5.Policy.ExtrinsicReward.sum": {
            "value": 298.4459930062294,
            "min": -597.2349941134453,
            "max": 428.1529925465584,
            "count": 10
        },
        "AgentVer5.Losses.PolicyLoss.mean": {
            "value": 0.024507668181322516,
            "min": 0.02112008537854611,
            "max": 0.025772494521612926,
            "count": 10
        },
        "AgentVer5.Losses.PolicyLoss.sum": {
            "value": 0.12253834090661259,
            "min": 0.08448034151418445,
            "max": 0.12886247260806463,
            "count": 10
        },
        "AgentVer5.Losses.ValueLoss.mean": {
            "value": 0.08938877473274867,
            "min": 0.07984275127450627,
            "max": 0.7894425420711438,
            "count": 10
        },
        "AgentVer5.Losses.ValueLoss.sum": {
            "value": 0.44694387366374333,
            "min": 0.35002891545494397,
            "max": 3.1577701682845754,
            "count": 10
        },
        "AgentVer5.Policy.LearningRate.mean": {
            "value": 1.6648054450680005e-05,
            "min": 1.6648054450680005e-05,
            "max": 0.00028458330513889997,
            "count": 10
        },
        "AgentVer5.Policy.LearningRate.sum": {
            "value": 8.324027225340002e-05,
            "min": 8.324027225340002e-05,
            "max": 0.0012843558718814,
            "count": 10
        },
        "AgentVer5.Policy.Epsilon.mean": {
            "value": 0.10554932000000002,
            "min": 0.10554932000000002,
            "max": 0.1948611,
            "count": 10
        },
        "AgentVer5.Policy.Epsilon.sum": {
            "value": 0.5277466000000001,
            "min": 0.5002040000000001,
            "max": 0.9281185999999999,
            "count": 10
        },
        "AgentVer5.Policy.Beta.mean": {
            "value": 0.0002869110680000001,
            "min": 0.0002869110680000001,
            "max": 0.004743568890000001,
            "count": 10
        },
        "AgentVer5.Policy.Beta.sum": {
            "value": 0.0014345553400000005,
            "min": 0.0014345553400000005,
            "max": 0.021413118140000003,
            "count": 10
        },
        "AgentVer5.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 10
        },
        "AgentVer5.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 10
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1744132356",
        "python_version": "3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\Buro\\DATN_MLAgentWithOpenAiGym\\venv\\Scripts\\mlagents-learn --run-id=Agent_Ver_5 --time-scale=4 --force",
        "mlagents_version": "1.1.0",
        "mlagents_envs_version": "1.1.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.6.0+cpu",
        "numpy_version": "1.23.5",
        "end_time_seconds": "1744150751"
    },
    "total": 18394.7925283,
    "count": 1,
    "self": 0.03147750000061933,
    "children": {
        "run_training.setup": {
            "total": 0.1317151000002923,
            "count": 1,
            "self": 0.1317151000002923
        },
        "TrainerController.start_learning": {
            "total": 18394.6293357,
            "count": 1,
            "self": 13.345720399523998,
            "children": {
                "TrainerController._reset_env": {
                    "total": 10.298195900000792,
                    "count": 1,
                    "self": 10.298195900000792
                },
                "TrainerController.advance": {
                    "total": 18370.889717200473,
                    "count": 508667,
                    "self": 11.996354099508608,
                    "children": {
                        "env_step": {
                            "total": 18194.275870600013,
                            "count": 508667,
                            "self": 17229.337214300125,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 956.0635069005875,
                                    "count": 508667,
                                    "self": 31.107227000204148,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 924.9562799003834,
                                            "count": 500033,
                                            "self": 924.9562799003834
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 8.875149399302245,
                                    "count": 508667,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 18370.188327999924,
                                            "count": 508667,
                                            "is_parallel": true,
                                            "self": 1712.7740095981208,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.00044969999908062164,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00023039999723550864,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.000219300001845113,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.000219300001845113
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 16657.413868701806,
                                                    "count": 508667,
                                                    "is_parallel": true,
                                                    "self": 50.345740701995965,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 38.18811420052043,
                                                            "count": 508667,
                                                            "is_parallel": true,
                                                            "self": 38.18811420052043
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 16415.937963498196,
                                                            "count": 508667,
                                                            "is_parallel": true,
                                                            "self": 16415.937963498196
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 152.9420503010915,
                                                            "count": 508667,
                                                            "is_parallel": true,
                                                            "self": 93.34025310076686,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 59.601797200324654,
                                                                    "count": 1017334,
                                                                    "is_parallel": true,
                                                                    "self": 59.601797200324654
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 164.61749250095272,
                            "count": 508667,
                            "self": 15.091812200189452,
                            "children": {
                                "process_trajectory": {
                                    "total": 52.398104500771296,
                                    "count": 508667,
                                    "self": 52.155627500771516,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.24247699999978067,
                                            "count": 1,
                                            "self": 0.24247699999978067
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 97.12757579999197,
                                    "count": 48,
                                    "self": 67.46290580007008,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 29.664669999921898,
                                            "count": 1440,
                                            "self": 29.664669999921898
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 1.0000003385357559e-06,
                    "count": 1,
                    "self": 1.0000003385357559e-06
                },
                "TrainerController._save_models": {
                    "total": 0.09570119999989402,
                    "count": 1,
                    "self": 0.02004020000094897,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.07566099999894504,
                            "count": 1,
                            "self": 0.07566099999894504
                        }
                    }
                }
            }
        }
    }
}